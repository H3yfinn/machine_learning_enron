{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/skl92/machine-learning-enron-email-analysis\n",
    "From the initial dataset, 5 new features where added, you can find more details in the table below:\n",
    "\n",
    "Feature\tDescription\n",
    "Ratio of POI messages\tPOI related messages divided over the total messages from the person\n",
    "Log of financials (multiple)\tFinancial variables with logarithmic transformation\n",
    "Square of financials (multiple)\tFinancial variables with squared transformation\n",
    "The reasoning behind the ratio of POI messages is that we expect that POI's contact each other relatively more often than with non-POI's and the relationship might be non-linear. We also can expect that the financial gains for POI's is actually non-linear, that is why applying a logarithmic and a square transformation to the original features, and it should improve many algorithms.\n",
    "\n",
    "It's quite reasonable to think that all the email features we have, 5 initial features plus 1 computed feature, really represent 1 underlying feature or principal component, something like increased amount of communication between POI's versus between POI's and non-POI's. The same goes for the financial features, which we could think are really measuring the POI's corruption via big money gains. In other words, we expect that a POI has a higher money gain compared to a non-POI, and that all the financial features are really trying to measure this underlying one. By tuning the parameters, we get the best classification results with 2 email components and 3 financial components. From the 29 features in total, they are reduced to 20 principal components.\n",
    "\n",
    "To tune the overall performance, both automated and manual tuning of parameters was involved. The automated tuned parameters where done using the GridSearchCV from SkLearn. The manual tuning occurred in the following ways:\n",
    "\n",
    "Including the PCA features\n",
    "Adding/removing features\n",
    "Scaling features\n",
    "For the most part, PCA made a huge improvement when the new features where added. PCA is kind of getting the best parts of the 29 features and cramming them up into 20. The new features really made the difference to push recall and precision up.\n",
    "\n",
    "To validate the performance of each algorithm, recall, precision and F1 scores where calculated for each one. You can find below a summary of the scores of the top algorithms.\n",
    "\n",
    "Feature\tF1 Score\tRecall\tPrecision\n",
    "Logistic Regression\t0.43820\t0.55400\t0.36245\n",
    "Results WILL vary. There is some randomness in the data splitting\t\t\t\n",
    "The best classifier was actually a Logistic Regression using PCA beforehand. This was achieved by using sklearn Pipline. The logistic regression achieved a consistent score above 0.30 for both precision and recall. The final parameters that were used are detailed below:\n",
    "\n",
    "Pipeline(steps=[('pca', PCA(copy=True, n_components=20, whiten=False)), ('logistic', LogisticRegression(C=100000000000000000000L, class_weight='auto', dual=False, fit_intercept=True, intercept_scaling=1, penalty='l2', random_state=42, tol=1e-10))])\n",
    "It seems that the most important parameter to tune was to set the class_weight to auto. I suspect this is due to the skewed nature of the dataset, because class weight assigns the importance of each class (POI or non-POI) depending on the inverse appearance of the class. So it set a much higher importance to POI's class which is exactly what we want in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://news.findlaw.com/hdocs/docs/enron/enron61702insiderpay.pdf\n",
    "-pdf with the financial data of all the poi's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/baumanab/udacity_intro_machinelearning_project\n",
    "Outliers\n",
    "\n",
    "Exploratory data analysis (scatter plot of scaled bonus vs. salary) revealed five outliers, one of which was eliminated from the data set.\n",
    "\n",
    "TOTAL: Extreme outlier for numerical features, consisting of spreadsheet summary artifact\n",
    "Four high rollers, including Lay and Skilling: While their values are extreme, these are legitimate values of actual POIs, so they were not eliminated.\n",
    "One other data point was eliminated (THE TRAVEL AGENCY IN THE PARK) because it does not represent a person, and therefore can’t be a POI, leaving 144 data points.\n",
    "While there is missing data, caution was observed in making any changes that might bias the models, therefore no effort was made to fill or impute values.\n",
    "\n",
    "What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that doesn’t come ready-made in the dataset--explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) If you used an algorithm like a decision tree, please also give the feature importances of the features that you use. [relevant rubric items: “create new features”, “properly scale features”, “intelligently select feature”]\n",
    "My approach to features was first to engineer features and eliminate problematic features. I engineered 3 features which focused on rate of interaction with known POIs: (1) poi_ratio: ratio of the total poi interaction (to, from, and shared emails) to the total emails sent (2) to_poi_ratio: ratio of total emails to a POI to total emails (3) from_poi_ratio: ratio of total emails from a POI to total emails. The rationale for addition of these features is that persons whom interacted with POI’s at higher rate (total interaction or to/from) may be colluding with those POIs to commit fraud and therefore be POIs themselves. Following this I removed the email address feature because it was not useful and created exceptions. Features were scaled with a min-max scaler prior to passing into select_k_best or PCA, to effect even weighting of features. This is essential to perform before either of these functions, considering the overall dynamic range of values (several orders of magnitude) and inherent differences in their units (i.e. dollars vs. fraction or number of emails). Either univariate feature selection (select K best), PCA or both were applied to the scaled features. I did not explicitly test my engineered features, but relied on select_k_best to pick the k most influential features. poi_ratio was scored as the 6th most influential feature. PCA revealed that 13 components accounted for 95% of the variance.\n",
    "\n",
    "Table1. 10 Best Features with Score and Percent Missing (NaN) Data\n",
    "\n",
    "Feature\tScore\tPercent_nan\n",
    "exercised_stock_options\t24.8\t29.9\n",
    "total_stock_value\t24.18\t13.2\n",
    "bonus\t20.79\t43.8\n",
    "salary\t18.29\t34.7\n",
    "deferred_income\t11.46\t66.7\n",
    "poi_ratio\t10.02\t40.3\n",
    "long_term_incentive\t9.92\t54.9\n",
    "restricted_stock\t9.21\t24.3\n",
    "total_payments\t8.77\t14.6\n",
    "shared_receipt_with_poi\t8.59\t40.3\n",
    "For exploration and tuning I tried a variety of feature numbers (k) and PCA components as well as a combination of univariate feature selection and PCA components. I tried the 5,6,8,9,10,11,12,and 15 best features; the PCA n_components = .98, .95, or .90, and the 5,6,8,9,10,11,12, and 15 best features piped through PCA with n_components = .98, .95, or .90. The value of k was changed manually but n_components was made part of GridSearchCV (change k, run search, evaluate, repeat). The 10 best features combined with PCA(n_components = .95) was consistently the top performing combination in terms of precision and recall. This combination accounted for 95% of the variance in 6 components. While I had originally decided to try PCA just to try it out and learn now to code up PCA, it ultimately became a critical part of my classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/shubhamlal11/enron-fraud-machine-learning\n",
    "Removing Features\n",
    "\n",
    "By apply some intuition, the following facts could be formulated :\n",
    "\n",
    "email_address can in no way differentiate between a POI and a non POI.\n",
    "\n",
    "Features like restricted_stock_deferred , director_fees, loan_advances contains majority of their values as NaN.\n",
    "\n",
    "Hence, these four features must be removed in order to gain better results.\n",
    "\n",
    "\n",
    "Creating New Features\n",
    "\n",
    "Instead of training the algorithm with the features like from_this_person_to_poi and from_messages, the ratio of number of messages from this person to poi and the total number of messages from this person would be more appropriate. Similar is the case with from_poi_to_this_person and to_messages.\n",
    "Main purpose of composing ratio of POI message is we expect POI contact each other more often than non-POI and the relationship could be non-linear. The initial assumption behind these features is: the relationship between POI is much more stronger than between POI and non-POIs\n",
    "New Features Created - fraction_from_this_person_to_poi and fraction_from_poi_to_this_person\n",
    "Features Removed - from_this_person_to_poi, from_poi_to_this_person, from_messages, to_messages\n",
    "\n",
    "\n",
    "Feature Selection\n",
    "\n",
    "I used scikit-learn SelectKBest to select best 10 influential features and used those featuers for all the upcoming algorithm. Unsurprisingly, 8 out of 10 features are related to financial data and only 2 features are related to e-mail.\n",
    "Selected Features\tScore\n",
    "exercised_stock_options\t8.772\n",
    "total_stock_value\t11.458\n",
    "bonus\t24.815\n",
    "salary\t18.289\n",
    "deferred_income_\t9.922\n",
    "long_term_incentive\t16.409\n",
    "restricted_stock_\t20.792\n",
    "total_payments_\t0.225\n",
    "shared_receipt_with_poi_\t9.212\n",
    "fraction_from_this_person_to_poi_\t3.128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "There are 146 samples with 20 features and a binary classification (\"poi\"), 2774 data points.\n",
    "Among 146 samples, there are 18 POI and 128 non-POI.\n",
    "Among 2774, there are 1358 (48.96%) data points with NaN values.\n",
    "https://olegleyz.github.io/enron_classifier.html \n",
    "https://www.kaggle.com/zichen/d/wcukierski/enron-email-dataset/explore-enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Really good series of insigfhts here: https://discussions.udacity.com/t/final-project-precision-and-recall/137020/22\n",
    "http://labhacker.com/articles/Enron-Fraud-Detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use this to get rid of nan values perhaps?\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
